{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20KMJ/ESAA7/blob/main/1003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ4cjh4r9R-J"
      },
      "source": [
        "# CHAPTER 02. 사이킷런으로 시작하는 머신러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p93CkhiQ9R-L"
      },
      "source": [
        "# 01. 사이킷런 소개와 특징"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C-7H7y09R-L"
      },
      "source": [
        "* 사이킷런(scikit-learn)은 파이썬 머신러닝 라이브러리 중 **가장 많이 사용**되는 라이브러리이다.\n",
        "* 파이썬 기반의 머신러닝은 곧 사이킷런으로 개발하는 것을 의미할 정도로 오랜 기간 파이썬 세계에서 인정받았으며, 사이킷런은 파이썬 기반의 머신러닝을 위한 **가장 쉽고 효율적인** 개발 라이브러리를 제공한다.\n",
        "* 물론 최근에는 **텐서플로, 케라스** 등 딥러닝 전문 라이브러리의 강세로 인해 대중적인 관심이 줄어들고는 있지만 여전히 많은 데이터 분석가가 의존하는 대표적인 파이썬 ML 라이브러리이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLJKBMBS9R-L"
      },
      "source": [
        "> **사이킷런의 특징**\n",
        "> * 쉽고 가장 파이썬스러운 API를 제공함 (파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향할 정도)\n",
        "> * 머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편리한 프레임워크와 API를 제공함\n",
        "> * 오랜 기간 실전 환경에서 검증됐으며, 매우 많은 환경에서 사용되는 성숙한 라이브러리임."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC-geUFn9R-M",
        "outputId": "98d047f5-2ca4-46a1-a1e6-1e54139ff6f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.23.2\n"
          ]
        }
      ],
      "source": [
        "# 사이킷런 버전 확인\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyi1tbU09R-N"
      },
      "source": [
        "# 02. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMEnEvkB9R-N"
      },
      "source": [
        "* 붓꽃 데이터 세트로 붓꽃의 품종을 분류(Classification)하는 머신러닝 모델을 만들어보자.\n",
        "* 붓꽃 데이터 세트는 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 비쳐(Feature)를 기반으로 꽃의 품종을 예측하기 위한 것이다.\n",
        "* 분류(Classification)은 대표적인 지도학습(Supervised Learning) 방법의 하나이다. **지도학습**은 학습을 위한 다양한 피처와 분류 결정값인 레이블(Label) 데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측한다. 즉 지도학습은 명확한 정답이 주어진 데이터를 먼저 학습한 뒤 미지의 정답을 예측하는 방식이다.\n",
        "* **학습 데이터 세트**: 학습을 위해 주어진 데이터 세트\n",
        "* **테스트 데이터 세트**: 머신러닝 모델의 예측 성능을 평가하기 위해 별도로 주어진 데이터 세트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ESY1E1M9R-N"
      },
      "outputs": [],
      "source": [
        "# 사이킷런에서 사용할 모듈 임포트\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwjq-_gh9R-N",
        "outputId": "08fb7a9e-615d-4d78-847d-a6c9cee6ec3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iris target값: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "iris target명: ['setosa' 'versicolor' 'virginica']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "\n",
              "   label  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트 로딩\n",
        "iris = load_iris()\n",
        "\n",
        "iris_data = iris.data\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# DataFrame으로 변환\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEd7K9pE9R-N"
      },
      "source": [
        "* 피쳐: sepal length, sepal width, petal length, petal width\n",
        "* 레이블(Label, 결정값): 0, 1 2\n",
        "> 0: Setosa 품종  \n",
        "> 1: versicolor 품종  \n",
        "> 2: virginica 품종  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AO_sg8q9R-O"
      },
      "source": [
        "### `train_test_split()` - 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2ooF3Ua9R-O"
      },
      "outputs": [],
      "source": [
        "# 학습용 데이터, 테스트용 데이터 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_label,\n",
        "                                                    test_size=0.2, random_state=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0M5JbZI9R-O"
      },
      "source": [
        "> * X_train: 학습용 피처 데이터 세트\n",
        "> * X_test: 테스트용 피처 데이터 세트\n",
        "> * y_train: 학습용 레이블 데이터 세트\n",
        "> * y_test: 테스트용 레이블 데이터 세트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmqGzF_j9R-O"
      },
      "source": [
        "> * iris_data: 피처 데이터 세트  \n",
        "> * iris_label: 레이블(Label) 데이터 세트  \n",
        "> * test_size=0.2: 전체 데이터 세트 중 테스트 데이터 세트의 비율  \n",
        "> * random_state: 호출할 때마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h8VDImT9R-P"
      },
      "source": [
        "### `DecisionTreeClassifier()` - 객체 생성\n",
        "### `fit()` - 학습\n",
        "### `predict()` - 예측\n",
        "### `accuracy_score()` - 정확도 측정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuUnefpz9R-P",
        "outputId": "0cbf96d8-d3e8-42c2-c1e7-23fa61fca3d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9333\n"
          ]
        }
      ],
      "source": [
        "# DecisionTreeClassifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습 수행\n",
        "dt_clf.fit(X_train, y_train)\n",
        "\n",
        "# 예측 수행\n",
        "pred = dt_clf.predict(X_test)\n",
        "\n",
        "# 정확도 측정\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE06xp8U9R-P"
      },
      "source": [
        "> 프로세스 정리\n",
        "> 1. **데이터 세트 분리**: 데이터를 학습 데이터와 테스트 데이터로 분리한다.\n",
        "> 2. **모델 학습**: 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습시킨다.\n",
        "> 3. **예측 수행**: 학습된 ML 모델을 이용해 테스트 데이터의 분류(즉, 붓꽃 종류)를 예측한다.\n",
        "> 4. **평가**: 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1QxWznI9R-P"
      },
      "source": [
        "# 03. 사이킷런의 기반 프레임워크 익히기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35RPoJ1l9R-Q"
      },
      "source": [
        "## Estimator 이해 및 fit(), predict() 메서드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIk7mbYS9R-Q"
      },
      "source": [
        "* **Classifier**: 분류 알고리즘을 구현한 클래스\n",
        "* **Regressor**: 회귀 알고리즘을 구현한 클래스\n",
        "* **Estimator**: 통칭"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6PIM_Kf9R-Q"
      },
      "source": [
        "> **분류 구현 클래스(Classifier)**  \n",
        "> DecisionTreeClassifier  \n",
        "> RandomForestClassifier  \n",
        "> GradientBoostingClassifier  \n",
        "> GaussianNB  \n",
        "> SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnakBeNV9R-Q"
      },
      "source": [
        "> **회귀 구현 클래스(Regression)**  \n",
        "> LinearRegression  \n",
        "> Ridge  \n",
        "> Lasso  \n",
        "> RandomForestRegressor  \n",
        "> GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxvUuVC59R-Q"
      },
      "source": [
        "## 사이킷런의 주요 모듈"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_jtN0TV9R-R"
      },
      "source": [
        "**예제 데이터**  \n",
        "* sklearn.datasets\n",
        "\n",
        "**피처 처리**  \n",
        "* sklearn.preprocessing\n",
        "* sklearn.feature_selection\n",
        "* sklearn.feature_extraction\n",
        "\n",
        "**피처 처리 & 차원 축소**  \n",
        "* sklearn.decomposition\n",
        "\n",
        "**데이터 분리, 검증 & 파라미터 튜닝**  \n",
        "* sklearn.model_selection\n",
        "\n",
        "**평가**  \n",
        "* sklearn.metrics\n",
        "\n",
        "**ML 알고리즘**  \n",
        "* sklearn.ensemble  \n",
        "* sklearn.linear_model  \n",
        "* sklearn.naive_bayes  \n",
        "* sklearn.neighbors  \n",
        "* sklearn.svm  \n",
        "* sklearn.tree  \n",
        "* sklearn.cluster\n",
        "\n",
        "**유틸리티**  \n",
        "* sklearn.pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOItTYNT9R-R"
      },
      "source": [
        "머신러닝 모델을 구축하는 일반적인 주요 프로세스(반복 수행):  \n",
        "**피처 처리(피처의 가공, 변경, 추출 수행) -> ML 알고리즘 학습/예측 수행 -> 모델 평가**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZJ9uHEy9R-R"
      },
      "source": [
        "## 내장된 예제 데이터 세트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AzCnuJm9R-R"
      },
      "source": [
        "분류나 회귀 연습용 예제 데이터\n",
        "* datasets.load_bostion() - 회귀 용도\n",
        "* datasets.load_breast_cancer() - 분류 용도\n",
        "* datasets.load_diabetes() - 회귀 용도\n",
        "* datasets.load_digits() - 분류 용도\n",
        "* datasets.load_iris() - 분류 용도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8tgVARa9R-S"
      },
      "source": [
        "fetch 계열\n",
        "* fetch_covtype()\n",
        "* fetch_20newsgroups()\n",
        "* fetch_olivetti_faces()\n",
        "* fetch_lfw_people()\n",
        "* fetch_lfw_pairs()\n",
        "* fetch_rcv1()\n",
        "* fetch_mldata()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5LCGjlL9R-S"
      },
      "source": [
        "분류와 클러스터링을 위한 표본 데이터 생성기\n",
        "* datasets.make_classifications()\n",
        "* datasets.make_blobs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlceiqEi9R-S",
        "outputId": "92f57da2-b2ec-4393-dd73-5e1f0246f1df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.utils.Bunch'>\n",
            "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
          ]
        }
      ],
      "source": [
        "# 붗꽃 데이터 세트 생성\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "\n",
        "# Bunch 클래스(딕셔너리 자료형과 유사)\n",
        "print(type(iris_data))\n",
        "\n",
        "# key 값 확인\n",
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnBnfM-b9R-S",
        "outputId": "19881700-ed5a-452b-87e2-f7d091ebe411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " feature_names의 type: <class 'list'>\n",
            " feature_names의 shape: 4\n",
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "\n",
            " target_names의 type: <class 'numpy.ndarray'>\n",
            " feature_names의 shape: 3\n",
            "['setosa' 'versicolor' 'virginica']\n",
            "\n",
            " data의 type: <class 'numpy.ndarray'>\n",
            " data의 shape: (150, 4)\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.2]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.6 1.4 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "\n",
            " target의 type: <class 'numpy.ndarray'>\n",
            " target의 shape: (150,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ],
      "source": [
        "print('\\n feature_names의 type:', type(iris_data.feature_names))\n",
        "print(' feature_names의 shape:', len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names의 type:', type(iris_data.target_names))\n",
        "print(' feature_names의 shape:', len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data의 type:', type(iris_data.data))\n",
        "print(' data의 shape:', iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n target의 type:', type(iris_data.target))\n",
        "print(' target의 shape:', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GLT_4fv9R-S"
      },
      "source": [
        "# 04. Model Selection 모듈 소개"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAUDgQue9R-S"
      },
      "source": [
        "### 학습/테스트 데이터 세트 분리 - train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCpJ6oe39R-S",
        "outputId": "c2f6f612-3cb9-47b7-a6e9-4e9404278008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 정확도: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 세트로 예측 수행\n",
        "pred = dt_clf.predict(train_data)\n",
        "print('예측 정확도:', accuracy_score(train_label, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y-SxKk-9R-S"
      },
      "outputs": [],
      "source": [
        "# 테스트 데이터 세트: 30%, 학습 데이터 세트: 70%\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "iris_data = load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target,\n",
        "                                                    test_size=0.3, random_state=121)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txs7bDXj9R-T",
        "outputId": "75fa6ca7-de12-43bc-8af2-85698aa9b63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측 정확도: 0.9556\n"
          ]
        }
      ],
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred = dt_clf.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOJh_Wmg9R-T"
      },
      "source": [
        "### 교차 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHDcpATm9R-T"
      },
      "source": [
        "#### 1. K 폴드 교차 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbeHS88O9R-T"
      },
      "source": [
        "* K개의 데이터 폴드 세트를 만들어서 K번만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\n",
        "* KFold와 StratifiedKFold 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZZpPpKE9R-T",
        "outputId": "c050ece2-f576-4e18-87dc-16ef44fd814f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ]
        }
      ],
      "source": [
        "# 붓꽃 데이터 세트\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:', features.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "js0cN_CL9R-T",
        "outputId": "0a879722-2224-4c87-eab9-ad43ebb79892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, 0.9)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체의 split()을 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "    # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "    # 반복 시마다 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계싼\n",
        "print('\\n## 평균 검증 정확도:'), np.mean(cv_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg4Z50fU9R-U"
      },
      "source": [
        "#### 2. Stratified K 폴드"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybic-pe-9R-U"
      },
      "source": [
        "* 불균형한(imbalanced) 분포도를 가진 레이블(결정 클래스) 데이터 집합을 위한 K 폴드 방식\n",
        "* **불균형한 분포**: 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vys4tJTx9R-U",
        "outputId": "c91e2551-9c79-4b5d-bfe2-0cc4e66b7910"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 붓꽃 데이터 세트 -> DataFrame으로 생성\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbM8yQgK9R-U",
        "outputId": "4b757592-4312-4f70-c017-c61eca3718ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# K 폴드 교차 검증\n",
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train=iris_df['label'].iloc[train_index]\n",
        "    label_test=iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2A_tRZP9R-U",
        "outputId": "78d413e9-5bca-4d16-a6c0-ebf623bc199c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Stratified K 폴드\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train=iris_df['label'].iloc[train_index]\n",
        "    label_test=iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajlzDCq79R-U",
        "outputId": "c163e3e8-ec4e-48f2-c27c-c112abb6713d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "#1 교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "## 교차 검증별 정확도: [0.98]\n",
            "## 평균 검증 정확도: 0.98\n",
            "\n",
            "#2 교차 검증 정확도:0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "## 교차 검증별 정확도: [0.98 0.94]\n",
            "## 평균 검증 정확도: 0.96\n",
            "\n",
            "#3 교차 검증 정확도:0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9666666666666667\n"
          ]
        }
      ],
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "# StratifiedKFold의 split() 호출시 반드시 ㄹ이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "    # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    # 학습 및 예측\n",
        "    dt_clf.fit(X_train, y_train)\n",
        "    pred = dt_clf.predict(X_test)\n",
        "    \n",
        "    # 반복 시마다 정확도 측정\n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도:{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter, test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "    # 교차 검증별 정확도 및 평균 정확도 계산\n",
        "    print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "    print('## 평균 검증 정확도:', np.mean(cv_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUFykHg-9R-U"
      },
      "source": [
        "### 교차 검증을 보다 간편하게 - cross_val_score()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMu2yJxO9R-V"
      },
      "source": [
        "* `cross_val_score()` API는 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜줌\n",
        "* 내부적으로 StratifiedKFold 이용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6gF5p7I9R-X",
        "outputId": "73c0bd0c-a537-45ea-ddba-0bc5e5bf8305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "평균 검증 정확도: 0.9667\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
        "scores = cross_val_score(dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도:', np.round(scores, 4))\n",
        "print('평균 검증 정확도:', np.round(np.mean(scores),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8vGPT-I9R-Y"
      },
      "source": [
        "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsY3-O-a9R-Y"
      },
      "outputs": [],
      "source": [
        "grid_parameters = {'max_depth':[1, 2, 3],\n",
        "                  'min_samples_split': [2,3]\n",
        "                  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U1Y-if9b9R-Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "## 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth':[1, 2, 3], 'min_samples_split':[2, 3]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDg6r65N9R-Y",
        "outputId": "6b43f764-8a95-4c9d-a93d-3ed8faad1b53"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>params</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>3</td>\n",
              "      <td>0.925</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
              "      <td>0.975000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.975</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     params  mean_test_score  rank_test_score  \\\n",
              "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
              "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
              "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
              "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
              "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
              "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  \n",
              "0              0.700                0.7               0.70  \n",
              "1              0.700                0.7               0.70  \n",
              "2              0.925                1.0               0.95  \n",
              "3              0.925                1.0               0.95  \n",
              "4              0.975                1.0               0.95  \n",
              "5              0.975                1.0               0.95  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정.\n",
        "### refit=True가 default임. True이면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가.\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THA1OvNJ9R-Y"
      },
      "source": [
        "* 일반적으로 학습 데이터를 GridSearchCV를 이용해 최적 하이퍼 파라미터 튜닝을 수행한 뒤에 별도의 테스트 세트에서 이를 평가하는 것이 일반적인 머신러닝 모델 적용 방법이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTekv2fZ9R-Y"
      },
      "source": [
        "# 05. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlgW779K9R-Y"
      },
      "source": [
        "## 데이터 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HFT8P-A9R-Y"
      },
      "source": [
        "* 레이블 인코딩(Label encoding)\n",
        "* 원-핫 인코딩(One Hot encoding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHfbZ80B9R-Z"
      },
      "source": [
        "> **레이블 인코딩(Label encoding)**\n",
        "> * 카테고리 피처를 코드형 숫자 값으로 변환하는 것\n",
        "> * LabelEncoder 클래스\n",
        "> * 선형 회귀와 같은 ML 알고리즘에는 적용하지 않아야 함 -> **원-핫 인코딩**이 이를 보완해줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIKz-_pb9R-Z",
        "outputId": "91e12c98-5d72-4a89-927d-7537dbca4e25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "인코딩 클래스: ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n",
            "인코딩 변환값: [0 1 4 5 3 3 2 2]\n",
            "디코딩 원본값: ['전자레인지' '컴퓨터' '믹서' 'TV' '냉장고' '냉장고' '선풍기' '선풍기']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 클래스:', encoder.classes_)\n",
        "print('인코딩 변환값:', labels)\n",
        "print('디코딩 원본값:', encoder.inverse_transform([4, 5, 2, 0, 1, 1, 3, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb5QW6mn9R-Z"
      },
      "source": [
        "> **원-핫 인코딩(One-Hot Encoding)**\n",
        "> * 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식\n",
        "> * 행 형태로 돼 있는 피처의 고유 값을 열 형태로 차원을 변환한 뒤, 고유 값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시함.\n",
        "> * 즉,해당 고유 값에 매칭되는 피처만 1이 되고 나머지 피처를 0을 입력함.\n",
        "> * OneHotEncoder 클래스\n",
        "> * OneHotEncoder로 변환하기 전, 모든 문자열 값이 숫자형 값으려 변환되어야 함!\n",
        "> * 2차원 데이터가 필요함\n",
        "> * get_dummies() : 원-핫 인코딩을 더 쉽게 지원하는 API로, 숫자형 값으로 변환 없이도 바로 변환이 가능함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3jv1JT89R-Z",
        "outputId": "83501302-ba3c-41ef-a2e0-671fe0ac6150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원-핫 인코딩 데이터\n",
            "[[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n",
            "원-핫 인코딩 데이터 차원\n",
            "(8, 6)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환합니다.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "# 2차원 데이터로 변환합니다.\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# 원-핫 인코딩을 적용합니다.\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUHbs8Vb9R-Z",
        "outputId": "8f39fd38-734c-42bc-95e4-790081b46867"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>item_TV</th>\n",
              "      <th>item_냉장고</th>\n",
              "      <th>item_믹서</th>\n",
              "      <th>item_선풍기</th>\n",
              "      <th>item_전자레인지</th>\n",
              "      <th>item_컴퓨터</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
              "0        1         0        0         0           0         0\n",
              "1        0         1        0         0           0         0\n",
              "2        0         0        0         0           1         0\n",
              "3        0         0        0         0           0         1\n",
              "4        0         0        0         1           0         0\n",
              "5        0         0        0         1           0         0\n",
              "6        0         0        1         0           0         0\n",
              "7        0         0        1         0           0         0"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "pd.get_dummies(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBJO8sHS9R-Z"
      },
      "source": [
        "## 피처 스케일링과 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGxFMwWD9R-Z"
      },
      "source": [
        "* 피처 스케일링(feature scaling): 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "* 대표적으로 표준화(Standardization), 정규화(Normalization)\n",
        "* 표준화: 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것\n",
        "* 정규화: 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념. 즉, 개별 데이터의 크기를 모두 똑같은 단위로 변경하는 것\n",
        "* 사이킷런에서 제공하는 대표적인 피처 스케일링 클래스: StandardScale, MinMaxScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2PjzhZl9R-Z"
      },
      "source": [
        "## StandardScaler\n",
        "* 표준화를 쉽게 지원하기 위한 클래스\n",
        "* 개별 피처를 평균이 0이고, 분산이 1인 값으로 변환해줌.\n",
        "* 사이킷런에서 구현한 RBF 커널을 이용하는 서포트 벡터 머신(Support Vector Machine)이나 선형 회귀(Linear Regression), 로지스틱 회귀(Logistic Regression)는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됐기 때문에 표준화를 적용하는 것은 예측 성능 향상에 중요한 요소가 됨."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tnArz_79R-Z",
        "outputId": "0c820972-7d6e-400a-98c4-9515c5c0e7fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)    5.843333\n",
            "sepal width (cm)     3.057333\n",
            "petal length (cm)    3.758000\n",
            "petal width (cm)     1.199333\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    0.685694\n",
            "sepal width (cm)     0.189979\n",
            "petal length (cm)    3.116278\n",
            "petal width (cm)     0.581006\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "# 붓꽃 데이터 세트를 로딩하고 Dataframe으로 변환\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df.var())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvKRoVZS9R-a",
        "outputId": "bae7a9e9-022e-4228-d046-335f12285722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature들의 평균 값\n",
            "sepal length (cm)   -1.690315e-15\n",
            "sepal width (cm)    -1.842970e-15\n",
            "petal length (cm)   -1.698641e-15\n",
            "petal width (cm)    -1.409243e-15\n",
            "dtype: float64\n",
            "\n",
            "feature들의 분산 값\n",
            "sepal length (cm)    1.006711\n",
            "sepal width (cm)     1.006711\n",
            "petal length (cm)    1.006711\n",
            "petal width (cm)     1.006711\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler 객체 생성\n",
        "scaler = StandardScaler()\n",
        "# StandardScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 평균 값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature들의 분산 값')\n",
        "print(iris_df_scaled.var())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8eCg7hz9R-a"
      },
      "source": [
        "* 모든 칼럼 값의 평균이 0에 아주 가까운 값으로, 그리고 분산은 1에 아주 가까운 값으로 변환됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBh5JnM59R-a"
      },
      "source": [
        "## MinMaxScaler\n",
        "* 데이터값을 0과 1 사이의 범위 값으로 변환함. 음수 값이 있으면 -1에서 1 값으로 변환함.\n",
        "* 데이터의 분포가 가우시안 분포가 아닐 경우에 Min, Max Scale을 적용해볼 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBMmcq2k9R-a",
        "outputId": "0df0d5b4-607c-4c42-da87-e193aba6558c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "feature들의 최솟값\n",
            "sepal length (cm)    0.0\n",
            "sepal width (cm)     0.0\n",
            "petal length (cm)    0.0\n",
            "petal width (cm)     0.0\n",
            "dtype: float64\n",
            "feature들의 최댓값\n",
            "sepal length (cm)    1.0\n",
            "sepal width (cm)     1.0\n",
            "petal length (cm)    1.0\n",
            "petal width (cm)     1.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "# transform() 시 스케일 변환된 데이터 세트가 NumPy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('feature들의 최댓값')\n",
        "print(iris_df_scaled.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIKyzaAQ9R-a"
      },
      "source": [
        "* 모든 피처에 0에서 1 사이의 값으로 변환되는 스케일링이 적용됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzEKSMtf9R-a"
      },
      "source": [
        "## 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFEXUMeO9R-a"
      },
      "source": [
        "* StandardScaler나 MinMaxScaler와 같은 Scaler 객체를 이용해 데이터의 스케일링 변환 시 **fit(), transform(), fit_transform()** 메소드를 이용함.\n",
        "* 주의가 필요한 부분: Scaler 객체를 이용해 학습 데이터 세트로 fit()과 transform()을 적용하면 테스트 데이터 세트로는 다시 fit()을 수행하지 않고 **학습 데이터 세트**로fit()을 수행한 결과를 이용해 transform() 변환을 적용해야 함.\n",
        "* 즉, **학습 데이터 세트**로 fit()이 적용된 스케일링 기준 정보를 **그대로** 테스트 데이터에 적용해야 ㅎ마."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8L7Xn4z9R-a"
      },
      "source": [
        "### 테스트 데이터에 fit()을 적용하면 어떤 문제가 발생하는지 살펴보자"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g48Gs50j9R-a",
        "outputId": "f462ce02-0d6a-4e97-e794-b42e26799210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "# Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원 변경\n",
        "train_array = np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange(0, 6).reshape(-1, 1)\n",
        "\n",
        "# MinMaxScaler 객체의 별도의 feature_range 파라미트 값을 지정하지 않으면 0~1 값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
        "scaler.fit(train_array)\n",
        "\n",
        "# 1/10 scale로 train_array 데이터 변환함. 원본 10 -> 1 로 변환됨.\n",
        "train_scaled = scaler.transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mHvgVjC9R-b",
        "outputId": "f641fe4a-6b27-4010-a6e4-964d94f34ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.2 0.4 0.6 0.8 1. ]\n"
          ]
        }
      ],
      "source": [
        "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 6로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "# 1/5 Scale로 test_array 데이터를 변환함. 원본 5 -> 1 로 변환.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "\n",
        "# test_array의 scale 변환 출력.\n",
        "print('원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkWr4x339R-b"
      },
      "source": [
        "* 학습 데이터와 테스트 데이터의 스케일링이 맞지 않음\n",
        "* 따라서 테스트 데이터에 다시 fit()을 적용해서는 안 되며 학습 데이터로 이미 fit()이 적용된 Scaler 객체를 이용해 transform()으로 변환해야 함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a25NiiZk9R-b"
      },
      "source": [
        "### 올바른 방법"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtFpQBE-9R-b",
        "outputId": "d5afb29e-ecb9-4af4-a29c-97eeacd209f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 train_array 데이터: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
            "Scale된 train_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
            "\n",
            "원본 test_array 데이터: [0 1 2 3 4 5]\n",
            "Scale된 test_array 데이터: [0.  0.1 0.2 0.3 0.4 0.5]\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler.transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 함.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터:', np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ataLQSSd9R-b"
      },
      "source": [
        "* train과 test 모두 올바르게 Scale 된 것을 확인할 수 있음.\n",
        "* fit_transform()을 적용할 때도 마찬가지임. 테스트 데이터에서는 절대 사용하면 안 됨!\n",
        "* 이렇게 학습과 테스트 데이터에 fit()과 transform()을 적용할 때 주의 사항이 발생하므로 학습과 테스트 데이터 세트로 분리하기 전에 먼저 **전체 데이터 세트에 스케일링을 적용**한 뒤 학습과 테스트 데이터 세트로 분리하는 것이 더 바람직함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOT-OUxj9R-b"
      },
      "source": [
        "> **요약**\n",
        "> 1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
        "> 2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5huMYvR9R-b"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}